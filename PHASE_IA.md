# PHASE IA - Booster Intelligence Artificielle

> **Philosophie** : L'IA est un **boost**, pas une n√©cessit√©. Le syst√®me doit √™tre 100% fonctionnel sans elle.
> **Contexte Agent** : √Ä lire avec [CONTEXT.md](file:///c:/Users/lecle/Workspace/saloon-management/CONTEXT.md)

---

## üéØ Objectif de cette Phase

Int√©grer une couche d'intelligence artificielle transversale qui simplifie la gestion du salon :
1. **Assistant de Gestion** (Langage naturel pour lancer des actions)
2. **Smart Scheduling** (Optimisation des rendez-vous)
3. **Insights & Business Intelligence** (Analyse des revenus et pr√©visions)
4. **G√©n√©ration de contenu** (Avatars, descriptions de services)

---

## üèóÔ∏è Architecture "AI-Ready" (Modularit√© & Fiabilit√©)

### 1. Graceful Degradation (Fonctionnement sans IA)
- **Feature Toggles** : Chaque fonctionnalit√© IA est activable/d√©sactivable dans les param√®tres.
- **Null Object Pattern** : Si l'IA est d√©sactiv√©e ou les tokens absents, le syst√®me utilise un `NullAIService` qui ne fait rien ou renvoie des r√©ponses par d√©faut, sans bloquer l'interface.
- **Fail-safe UI** : Les boutons "IA" sont masqu√©s ou gris√©s si le service est indisponible.

### 2. Mod√®le de Co√ªt & Choix des LLM
- **Backend Proxy** : Le frontend ne parle pas directement aux API (OpenAI/Anthropic). Tout passe par le backend Go.
- **Model Selection** : L'utilisateur peut choisir son mod√®le dans les param√®tres (GPT-4o, Claude 3.5 Sonnet, Gemini 1.5, ou des mod√®les locaux/low-cost via Ollama).
- **Caching** : Les r√©ponses IA co√ªteuses sont mises en cache dans Redis.

---

## üì¶ Livrables de cette Phase

### 1. Infrastructure IA (Backend Go)
- [ ] `internal/infrastructure/ai/` : Client g√©n√©rique supportant plusieurs fournisseurs (OpenAI, Anthropic, Google).
- [ ] `internal/infrastructure/ai/factory.go` : Pour switcher de mod√®le √† la vol√©e.
- [ ] Endpoint `/api/v1/ai/chat` : Interface de commande en langage naturel.

### 2. UI IA (Frontend)
- [ ] `frontend/context/AIContext.tsx` : G√®re le statut de l'IA (active/inactive), les erreurs de tokens et le mod√®le choisi.
- [ ] `frontend/components/ai/AICommandCenter.tsx` : Barre de commande rapide (CMD+K) pour piloter le salon.
- [ ] `frontend/components/ui/AIBadge.tsx` : Indicateur visuel pour les suggestions intelligentes.

### 3. Fonctionnalit√©s "Smart"
- [ ] **Smart Add** : "Ajoute un client nomm√© David avec le num√©ro 06..." (Parse via LLM puis appel API).
- [ ] **Insight Summary** : "R√©sume moi la journ√©e de demain" (Analyse des bookings).
- [ ] **Data Cleansing** : D√©tection des doublons dans les clients.

---

## üìù √âtape par √âtape

### √âtape IA.1 : Configuration & Context

#### Fichier : `frontend/context/AIContext.tsx`

```typescript
'use client';

import React, { createContext, useContext, useState, useEffect } from 'react';

interface AIConfig {
  isEnabled: boolean;
  provider: 'openai' | 'anthropic' | 'gemini' | 'ollama';
  model: string;
  hasValidToken: boolean;
}

const AIContext = createContext<{ config: AIConfig; updateConfig: (c: Partial<AIConfig>) => void } | undefined>(undefined);

export function AIProvider({ children }: { children: React.ReactNode }) {
  const [config, setConfig] = useState<AIConfig>({
    isEnabled: false,
    provider: 'openai',
    model: 'gpt-4o-mini', // Option low-cost par d√©faut
    hasValidToken: false,
  });

  // TODO: Charger la config depuis le backend/localStorage au montage

  const updateConfig = (newConfig: Partial<AIConfig>) => {
    setConfig(prev => ({ ...prev, ...newConfig }));
  };

  return (
    <AIContext.Provider value={{ config, updateConfig }}>
      {children}
    </AIContext.Provider>
  );
}

export const useAI = () => {
  const ctx = useContext(AIContext);
  if (!ctx) throw new Error('useAI must be used within AIProvider');
  return ctx;
};
```

### √âtape IA.2 : Le Proxy IA (Backend Go)

#### Structure : `backend/internal/infrastructure/ai/`
L'interface `LLMClient` d√©finit les m√©thodes communes (GenerateText, ParseSchema).

```go
type LLMProvider interface {
    Chat(ctx context.Context, prompt string) (string, error)
}
```

---

## ‚úÖ Crit√®res de Succ√®s

1. **V√©rification "Off"** : Si je coupe l'IA, je peux toujours cr√©er un client manuellement sans aucune erreur console.
2. **Modularit√©** : Je peux passer de GPT-4o √† Claude 3 sur une simple option de r√©glage.
3. **Erreurs propres** : Si le token est expir√©, une notification discr√®te informe l'utilisateur mais ne bloque pas l'app.
4. **Productivit√©** : L'ajout d'un client complexe par la barre de commande IA prend moins de 5 secondes.

---

## üí° Cas d'usage "Boost" (Le quotidien)

- **Le matin** : "Bonjour, quels sont mes 3 cr√©neaux vides les plus importants √† remplir aujourd'hui ?"
- **Face au client** : L'IA sugg√®re : "Ce client n'est pas venu depuis 3 mois, proposez-lui la promotion X."
- **Fin de mois** : "Analyse la baisse de revenu du Worker Marie et sugg√®re des actions."

---

**Derni√®re mise √† jour** : 2026-01-18
**Phase active** : S'intercale entre la Phase 1 et 2 (Init core IA).
